{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0695dc62",
   "metadata": {},
   "source": [
    "# Library Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0066cc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !pip install datasets\n",
    "# !pip install wordninja\n",
    "# !pip install textblob\n",
    "# !pip install nltk\n",
    "# !pip install sentence-transformers\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# !pip install swifter\n",
    "# !pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffd5d06",
   "metadata": {},
   "source": [
    "# Import Libraries + Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75a29d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import re\n",
    "import swifter\n",
    "import gensim.downloader as api\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import string\n",
    "import wordninja\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import warnings\n",
    "\n",
    "from datasets import load_dataset\n",
    "from spellchecker import SpellChecker\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import Word\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from torch.optim import AdamW\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import DistilBertForSequenceClassification,DistilBertModel, DistilBertTokenizer\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "# suppress UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "\n",
    "word2vec_model = api.load(\"word2vec-google-news-300\")\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aced7f7f",
   "metadata": {},
   "source": [
    "# Fetch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f48f45d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'relation'],\n",
       "        num_rows: 8000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'relation'],\n",
       "        num_rows: 2717\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dataset(\"sem_eval_2010_task_8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bab200",
   "metadata": {},
   "source": [
    "NOTE: This dataset doesnot contain any validation set, hence validation is splitting the training set"
   ]
  },
  {
   "cell_type": "raw",
   "id": "60fb9850",
   "metadata": {},
   "source": [
    "Training Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8c6ddd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(load_dataset(\"sem_eval_2010_task_8\", split = \"train\"))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ad15d82",
   "metadata": {},
   "source": [
    "Testing Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e5fbea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(load_dataset(\"sem_eval_2010_task_8\", split = \"test\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc093e4",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be43046",
   "metadata": {},
   "source": [
    "Functions to extract features, improve data quality and more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c6662c",
   "metadata": {},
   "source": [
    "### 1. Extract Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "672f4f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[0]['sentence']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9941ad",
   "metadata": {},
   "source": [
    "Sentence contains entities enclosed in '<>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19ba7d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(sentence):\n",
    "    try:\n",
    "        e1 = re.search(r'<e1>(.*?)</e1>', sentence).group(1).lower().strip()\n",
    "        e2 = re.search(r'<e2>(.*?)</e2>', sentence).group(1).lower().strip()\n",
    "    except:\n",
    "        # raise error if entities are not enclosed in '<>' in sentence\n",
    "        raise ValueError('Sentence passed is not in correct format')\n",
    "    return pd.Series([e1, e2], index=['e1', 'e2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f1dcd7",
   "metadata": {},
   "source": [
    "### 2. Synset Check"
   ]
  },
  {
   "cell_type": "raw",
   "id": "95890588",
   "metadata": {},
   "source": [
    "Pre-trained wordnet module was implemented to convert text to vectors using following checks:\n",
    "1. Basic text's synset was searched pre-trained model\n",
    "2. If not found, text was capitalsied and then searched \n",
    "3. If not found, hyphenated texts were unhyphenated and then searched\n",
    "4. If not found, texts are converted into base form (singular, present tense) and then searched\n",
    "5. If not found, and there exists more than one word, the last word is searched\n",
    "6. If not found, and there exists more than one word, the first word is searched\n",
    "7. If not found, some rule-based word tunings are applied and check (removed 'er' at the end, removed 'ment' at the end)\n",
    "8. If not found, spelling mistakes are corrected, if any, and then searched\n",
    "9. If not found, the words are broken into segments where both words make sense (eg. floodwaters -> flood and waters) and the longer word, then last word and then first word is searched\n",
    "10. If still not found, zero vector is assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7135e365",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell_checker = SpellChecker(distance=1)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "count = 0\n",
    "\n",
    "def synset_check(text,sentence):\n",
    "    global count\n",
    "    return_text = ''\n",
    "    \n",
    "    try:\n",
    "        text = int(text[0])\n",
    "        text = 'number'\n",
    "    except:\n",
    "        pass\n",
    "   \n",
    "    if wordnet.synsets(text): # 1. search text \n",
    "        return_text = text\n",
    "    \n",
    "    elif wordnet.synsets(text.capitalize()): # 2. search capitalised text \n",
    "        return_text = text.capitalize()\n",
    "        \n",
    "    elif wordnet.synsets(text.replace('-','')): # 3. remove hyphen and search\n",
    "        return_text = text.replace('-','')\n",
    "        \n",
    "    elif wordnet.synsets(str(lemmatizer.lemmatize(text, pos='n'))): # 4. convert to singular and then search\n",
    "        return_text = str(lemmatizer.lemmatize(text, pos='n'))\n",
    "        \n",
    "    elif wordnet.synsets(str(lemmatizer.lemmatize(text, pos='n')).capitalize()): # 5. convert to singular & capitalise and then search\n",
    "        return_text = str(lemmatizer.lemmatize(text, pos='n')).capitalize()\n",
    "        \n",
    "    elif wordnet.synsets(str(Word(text).lemmatize())): # 6. convert past to present and search\n",
    "        return_text = str(Word(text).lemmatize())\n",
    "    \n",
    "    elif wordnet.synsets(text.replace('-',' ').split()[-1]): # 7. if >1 words, search last word\n",
    "        return_text = text.replace('-',' ').split()[-1]\n",
    "        \n",
    "    elif wordnet.synsets(text.replace('-',' ').split()[0]): # 8. if >1 words, search first word\n",
    "        return_text = text.replace('-',' ').split()[0]\n",
    "        \n",
    "    # some custom defined rules\n",
    "    # 1. 'er' cases\n",
    "    elif str(Word(text).lemmatize())[-2:]=='er' and wordnet.synsets(str(Word(text).lemmatize())[:-2]): # 9. remove last 'er' of word and search\n",
    "        return_text = str(Word(text).lemmatize())[:-2]\n",
    "        \n",
    "    # 2. 'ment' cases\n",
    "    elif str(Word(text).lemmatize())[-4:]=='ment' and wordnet.synsets(str(Word(text).lemmatize())[:-4]): # 10. remove last 'ment' of word and search\n",
    "        return_text = str(Word(text).lemmatize())[:-4]\n",
    "    \n",
    "    elif wordnet.synsets(str(spell_checker.correction(text))): # 11. correct spelling, if any, and search\n",
    "        return_text = str(spell_checker.correction(text))\n",
    "    \n",
    "    elif wordninja.split(nlp(text)[0].lemma_)!=[] and wordnet.synsets(max(wordninja.split(nlp(text)[0].lemma_), key=len)): # 12. split words into segment and search the longest word\n",
    "        return_text = max(wordninja.split(nlp(text)[0].lemma_), key=len)\n",
    "\n",
    "    elif wordninja.split(nlp(text)[0].lemma_)!=[] and wordnet.synsets(str(wordninja.split(nlp(text)[0].lemma_)[-1])): # 13. split words into segment and search the last word\n",
    "        return_text = str(wordninja.split(nlp(text)[0].lemma_)[-1])\n",
    "    \n",
    "    elif wordninja.split(nlp(text)[0].lemma_)!=[] and wordnet.synsets(str(wordninja.split(nlp(text)[0].lemma_)[0])): # 14. split words into segment and search the first word\n",
    "        return_text = str(wordninja.split(nlp(text)[0].lemma_)[0])\n",
    "\n",
    "    else:\n",
    "        pass    \n",
    "    \n",
    "    if return_text =='':\n",
    "        count = count+1\n",
    "        return_text = text\n",
    "\n",
    "    return_sentence = sentence.replace(text, return_text)\n",
    "    match = re.search(r\"<e1>(.*?)</e2>\", return_sentence)\n",
    "    if match:\n",
    "        trimmed_sentence = (match.group(1))  # Extract the captured group (trip information)\n",
    "    else:\n",
    "        trimmed_sentence = None\n",
    "    \n",
    "    # remove entity tags '<>'\n",
    "    return_sentence = re.sub(r\"<[^>]+>\", \"\",return_sentence)\n",
    "    trimmed_sentence = re.sub(r\"<[^>]+>\", \"\",trimmed_sentence)\n",
    "    # remove punctuations\n",
    "    punctuation_set = ''.join(char for char in string.punctuation)\n",
    "    return_sentence = return_sentence.translate(str.maketrans('', '', punctuation_set))\n",
    "    trimmed_sentence = trimmed_sentence.translate(str.maketrans('', '', punctuation_set))\n",
    "    # remove extra spaces\n",
    "    return_sentence = re.sub(r\"\\s+\", \" \", return_sentence).strip()\n",
    "    trimmed_sentence = re.sub(r\"\\s+\", \" \", trimmed_sentence).strip()\n",
    "        \n",
    "    \n",
    "    return pd.Series([return_sentence, return_text, trimmed_sentence], index=['corrected_sentence', 'e', 'trimmed_sentence'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae83568",
   "metadata": {},
   "source": [
    "### 3. Custom Entity Disambiguation "
   ]
  },
  {
   "cell_type": "raw",
   "id": "abefb445",
   "metadata": {},
   "source": [
    "Extract the actual meaning of entities in the sentence (contextual meaning) using custom logic\n",
    "1. Fetch the synsets of the entities (broader categories)\n",
    "2. Extract the definitions of the synsets\n",
    "3. Find the cosine similarity of the main words (adjectives, nouns and verbs) in the definition and the sentence (excluding the entity word)\n",
    "4. The synset definition with most similarity with sentence is selected as the synset\n",
    "5. Once both entities synset have been derived, their lowest common hypernym is also extract to understand their relationship"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f5a66df7",
   "metadata": {},
   "source": [
    "1. SYNSET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f0fa8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_synsets(word):\n",
    "    words = word.replace('-',' ').split(' ')\n",
    "    new_words = []\n",
    "    \n",
    "    for item in words:\n",
    "        try:\n",
    "            new_words = new_words + wordninja.split(nlp(item)[0].lemma_)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    for j in words:\n",
    "        for i in range(1,len(j)):\n",
    "            prefix = j[:i]\n",
    "            suffix = j[i:]\n",
    "            if wordnet.synsets(prefix) and wordnet.synsets(suffix):\n",
    "\n",
    "                new_words = [prefix,suffix] + new_words\n",
    "            elif wordnet.synsets(prefix) and len(prefix)>=5:\n",
    "                new_words = [prefix] + new_words\n",
    "            elif wordnet.synsets(suffix) and len(suffix)>=5:\n",
    "                new_words = [suffix] + new_words\n",
    "\n",
    "    new_words = [item for item in new_words if len(item) >= 3]\n",
    "        \n",
    "    synsets = []\n",
    "    for item in new_words:\n",
    "        item_synset = wordnet.synsets(item)\n",
    "        synsets = synsets + item_synset\n",
    "    return synsets\n",
    "\n",
    "    \n",
    "\n",
    "def filter_main_tokens(sentence):\n",
    "\n",
    "    doc = nlp(sentence)\n",
    "    # filtering based on POS tags\n",
    "    filtered_tokens = [token.text for token in doc if token.pos_ in (\"NOUN\", \"VERB\", \"ADJ\")]\n",
    "\n",
    "    return filtered_tokens\n",
    "    \n",
    "\n",
    "def disambiguate_entity_in_sentence(sentence, word, flag):\n",
    "    \n",
    "    # main tokens of the sentence\n",
    "    sentence_tokens = filter_main_tokens(sentence.replace(word,''))\n",
    "    \n",
    "    # fetch synsets for the word\n",
    "    synsets = wordnet.synsets(word.replace(' ','_'))\n",
    "    \n",
    "    # handle british vs american english\n",
    "    if len(synsets)==0 and word.count('s')==1:\n",
    "        synsets = wordnet.synsets(word.replace('s','z'))\n",
    "    if len(synsets)==0 and word.count('z')==1:\n",
    "        synsets = wordnet.synsets(word.replace('z','s'))\n",
    "        \n",
    "    # custom synset extraction by segmenting words\n",
    "    if len(synsets)==0:\n",
    "        synsets = segment_synsets(word)\n",
    "    \n",
    "    if len(synsets)==0:\n",
    "        print ('Synset for \"'+word+'\" NOT FOUND')  \n",
    "    \n",
    "    # fetch the most relatable synset based on sentence\n",
    "    scores = {}\n",
    "    for synset in synsets:\n",
    "        synset_tokens = filter_main_tokens(synset.definition())\n",
    "\n",
    "        synset_embeddings = [word2vec_model[token] for token in synset_tokens if token in word2vec_model]\n",
    "        \n",
    "        if len(synset_embeddings)>0:\n",
    "            avg_synset_embedding = np.mean(synset_embeddings, axis=0)\n",
    "            # calculate similarity score based on cosine similarity between avg_synset_embedding and each token in sentence\n",
    "            similarity_scores = [np.dot(avg_synset_embedding, word2vec_model[token])/(np.linalg.norm(avg_synset_embedding)*np.linalg.norm(word2vec_model[token]))\n",
    "                                 for token in sentence_tokens if token in word2vec_model]\n",
    "            scores[synset] = np.mean(similarity_scores)\n",
    "        \n",
    "        else:\n",
    "            scores[synset] = 0\n",
    "    \n",
    "    # extract the highest score synset\n",
    "    if len(synsets)>0:\n",
    "        best_synset = max(scores, key=scores.get)\n",
    "        \n",
    "    else:\n",
    "        best_synset = wordnet.synsets('unavailable')[0]\n",
    "        flag = flag+1\n",
    "    e_definition = best_synset.definition()\n",
    "    \n",
    "    return pd.Series([best_synset, e_definition, flag], index=['e_synset', 'e_definition', 'flag'])\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "72956771",
   "metadata": {},
   "source": [
    "2. HYPERNYM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ab38947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hypernym(synset1, synset2):\n",
    "    common_hypernym = synset1.lowest_common_hypernyms(synset2)\n",
    "    return common_hypernym[0].lemmas()[0].name() if common_hypernym else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9c4b03",
   "metadata": {},
   "source": [
    "### 4. Extract Features"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d617e435",
   "metadata": {},
   "source": [
    "Extra features wrt entities:\n",
    "    1. entities POS tag\n",
    "    2. dependency parsing: entity dependent token and their pos tag\n",
    "    3. tokens before and after entities\n",
    "    4. words between entities: total words and pos tags\n",
    "    5. entities position: start and end (based on letters and tokens)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "533bb08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(e1, e2, sentence):\n",
    "\n",
    "    \n",
    "    doc = nlp(sentence)\n",
    "\n",
    "    e1_dep_token, e2_dep_token = 'NA.', 'NA.'\n",
    "    e1_prev_token, e2_prev_token = 'NA.', 'NA.'\n",
    "    e1_post_token, e2_post_token = 'NA.', 'NA.'\n",
    "\n",
    "    e1_post_memory = e2_post_memory = False\n",
    "    memory = 'NA.'\n",
    "\n",
    "    for token in doc:\n",
    "        \n",
    "        if e1_post_memory == True:\n",
    "            e1_post_token = str(token)\n",
    "        e1_post_memory = False\n",
    "        \n",
    "        if e2_post_memory == True:\n",
    "            e2_post_token = str(token)\n",
    "        e2_post_memory = False\n",
    "        \n",
    "        if str(token) in e1.split():            \n",
    "            e1_dep_token = str(token.head)\n",
    "            \n",
    "            if e1_prev_token == 'NA.':\n",
    "                e1_prev_token = memory\n",
    "                \n",
    "            e1_post_memory = True\n",
    "            \n",
    "        if str(token) in e2.split(): \n",
    "            e2_dep_token = str(token.head)\n",
    "            \n",
    "            if e2_prev_token == 'NA.':\n",
    "                e2_prev_token = memory\n",
    "                \n",
    "            e2_post_memory = True\n",
    "\n",
    "        memory = str(token)\n",
    "    \n",
    "    return pd.Series([e1_dep_token, e1_prev_token, e1_post_token, e2_dep_token, e2_prev_token, e2_post_token],\n",
    "                     index=['e1_dep_token', 'e1_prev_token', 'e1_post_token', 'e2_dep_token', 'e2_prev_token', 'e2_post_token'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac09ce4f",
   "metadata": {},
   "source": [
    "### 5. Sentence Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9c06983c",
   "metadata": {},
   "source": [
    "Select the important part of the sentence which focuses on the relation between entities\n",
    "1. Strip sentence between entity occurences only\n",
    "2. Include both the entities in the modified sentence\n",
    "3. Keep only the tokens having POS tags of verb, auxilliary verb and adjectives between the entities\n",
    "4. Add the meaning of the entities at the end of the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85ad0298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_sentence(new_sentence, e1, e2, e1_def, e2_def):\n",
    "    \n",
    "    doc = nlp(new_sentence)\n",
    "    return_sentence = ''\n",
    "    prev_word_pos = ''\n",
    "    prev_word = ''\n",
    "    sentence_entry = False\n",
    "    \n",
    "    # strip sentence between entities and select important tokens\n",
    "    for word in doc:\n",
    "        if str(word) == e1 and sentence_entry == False:\n",
    "            sentence_entry = True\n",
    "            end_type = e2\n",
    "        if str(word) == e2 and sentence_entry == False:\n",
    "            sentence_entry = True\n",
    "            end_type = e1\n",
    "            \n",
    "        if (str(word) == e1 or str(word) == e2 or word.pos_ in ['ADP', 'AUX','VERB', 'X']) and sentence_entry==True:\n",
    "\n",
    "            if word.pos_ =='ADP' and not(prev_word_pos in ['AUX','VERB', 'X'] or prev_word == e1 or prev_word == e2):\n",
    "                pass\n",
    "            else:\n",
    "                return_sentence = return_sentence + ' ' + word.text\n",
    "            \n",
    "            prev_word_pos = word.pos_\n",
    "            prev_word = str(word)\n",
    "            \n",
    "            if end_type == str(word):\n",
    "                sentence_entry = False\n",
    "                break\n",
    "                \n",
    "    # extract entity definition tokens\n",
    "    def definition_tokens(doc):\n",
    "        new_def = ''\n",
    "        for word in doc:\n",
    "            if (word.pos_ in ['ADP', 'AUX','VERB', 'X', 'NOUN']):\n",
    "                new_def = new_def + ' ' + word.text\n",
    "        return new_def\n",
    "    \n",
    "    new_e1_def = definition_tokens(nlp(e1_def))\n",
    "    new_e2_def = definition_tokens(nlp(e2_def))\n",
    "                  \n",
    "    return pd.Series([return_sentence[1:], \n",
    "                      return_sentence[1:].strip() +' where '+e1+' is the '+new_e1_def.strip()+' and '+e2+' is the '+new_e2_def.strip()],\n",
    "                     index=['trimmed_sentence', 'trimmed_sentence_wdef'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c33c454",
   "metadata": {},
   "source": [
    "### Apply All Functions-Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbc25044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df_original):\n",
    "    df = df_original.copy()\n",
    "    df[['e1','e2']] = df['sentence'].swifter.apply(extract_entities)\n",
    "    df['warning_flags'] = 0\n",
    "    df[['corrected_sentence','corrected_e1','trimmed_sentence']] = df.swifter.apply(lambda x: synset_check(x['e1'],x['sentence']),axis=1)\n",
    "    df[['corrected_sentence','corrected_e2','trimmed_sentence']] = df.swifter.apply(lambda x: synset_check(x['e2'],x['sentence']),axis=1)\n",
    "    df[['e1_synset','e1_definition','warning_flags']] = df.swifter.apply(lambda x: disambiguate_entity_in_sentence(x['corrected_sentence'],x['corrected_e1'],x['warning_flags']), axis=1)\n",
    "    df[['e2_synset','e2_definition','warning_flags']] = df.swifter.apply(lambda x: disambiguate_entity_in_sentence(x['corrected_sentence'],x['corrected_e2'],x['warning_flags']), axis=1)\n",
    "    df[['e1_dep_token', 'e1_prev_token', 'e1_post_token', 'e2_dep_token', 'e2_prev_token', 'e2_post_token']] = df.swifter.apply(lambda x: extract_features(x['corrected_e1'],x['corrected_e2'],x['corrected_sentence']), axis=1)\n",
    "    df[['trimmed_sentence', 'trimmed_sentence_wdef']] = df.swifter.apply(lambda x: tune_sentence(x['trimmed_sentence'],x['corrected_e1'],x['corrected_e2'],x['e1_definition'],x['e2_definition']),axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bc9b32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc1ba5e241734cc8b43bba4b618ca9ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/8000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8fa921b63a14027978b80d8311dfb8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/8000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1188c0a359f4a6d98dfbb2a6113a13d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/8000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "358863ad8d8c48a4a06eeaee71dc0a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/8000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset for \"natron\" NOT FOUND\n",
      "Synset for \"opioids\" NOT FOUND\n",
      "Synset for \"joey\" NOT FOUND\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9251ac3fafb4963b21c1053b27574b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/8000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e024337f4546b3b9b34189e761e5b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/8000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f048e97eed154d0a876e85959c85933c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/8000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75d4fd737b3456b9435e212e18ff88a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/2717 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b4b5c1217049578e6756c9bd0efe76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/2717 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b253a425e9c4472396d1e13dcf803fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/2717 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11146b83072459d83750a54f26c70a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/2717 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset for \"kimchi\" NOT FOUND\n",
      "Synset for \"tempeh\" NOT FOUND\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5720cdf654ef4505965d2d0cf614d3d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/2717 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset for \"wiki\" NOT FOUND\n",
      "Synset for \"prequels\" NOT FOUND\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b84d9dac6b49a68f6db658be4c539d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/2717 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "240d8a8605024112ab858a9b8a8ff917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/2717 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = preprocess_data(train_df)\n",
    "test_df = preprocess_data(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e164b7f8",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6501c853",
   "metadata": {},
   "source": [
    "### 1. Model Training & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af7caf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(columns=['relation']) \n",
    "y = train_df['relation']  \n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "X_train = X_train[X_train['warning_flags']==0]\n",
    "X_train['relation'] = y_train\n",
    "X_val['relation'] = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9519359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationExtraction(torch.nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(RelationExtraction, self).__init__()\n",
    "\n",
    "        self.bert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.dropout1 = torch.nn.Dropout(p=0.05)\n",
    "        self.fc1 = torch.nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "        \n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "\n",
    "        outputs = self.bert(input_ids, attention_mask)\n",
    "        \n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        pooled_output = torch.mean(last_hidden_state, dim=1) \n",
    "        \n",
    "        pooled_output = self.dropout1(pooled_output)\n",
    "        output = self.fc1(pooled_output)\n",
    "        logits = output\n",
    " \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37bc6e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_model(train_df, test_df, epochs=5, batchsize=32, device=None):\n",
    "\n",
    "    model = RelationExtraction(num_labels=len(train_df['relation'].unique())+1)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5) \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    \n",
    "    def tokenize_batch(df, batchsize=32):\n",
    "        tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "        tokenized_inputs = tokenizer(df['trimmed_sentence_wdef'].tolist(),\n",
    "                                     df['corrected_e1'].tolist(),\n",
    "                                     df['corrected_e2'].tolist(),\n",
    "                                     df['e1_dep_token'].tolist(),\n",
    "                                     df['e2_dep_token'].tolist(),\n",
    "                                     padding=True, \n",
    "                                     truncation=True,\n",
    "                                     return_tensors='pt')\n",
    "        labels =  torch.tensor(df['relation'].tolist())\n",
    "\n",
    "        \n",
    "        dataset = TensorDataset(tokenized_inputs['input_ids'], tokenized_inputs['attention_mask'], labels)\n",
    "        loader = DataLoader(dataset, batch_size=batchsize)\n",
    "        \n",
    "        return loader\n",
    "    \n",
    "    def train_validate(model, optimizer, criterion ,epochs, device):\n",
    "        \n",
    "        torch.manual_seed(42)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            print('********EPOCH', epoch+1, 'TRAINING********')\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "\n",
    "            for batch in tqdm(tokenize_batch(train_df), total=int(len(train_df)/batchsize)):\n",
    "\n",
    "                input_ids, attention_mask, labels = batch\n",
    "\n",
    "                if device:  \n",
    "                    input_ids = input_ids.to(device)\n",
    "                    attention_mask = attention_mask.to(device)\n",
    "                    labels = torch.tensor(labels).to(device)\n",
    "\n",
    "                outputs = model(input_ids, attention_mask)\n",
    "                logits = outputs\n",
    "\n",
    "                loss = criterion(logits, labels)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "            # Print average loss per epoch\n",
    "            avg_loss = total_loss / len(train_df)\n",
    "            print(f\"Epoch {epoch+1}/{epochs} | Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "\n",
    "            model.eval()\n",
    "            total_eval_loss = 0\n",
    "            total_correct = 0\n",
    "            pred_list = []\n",
    "            label_list = []\n",
    "            \n",
    "            print('********EPOCH', epoch+1, 'VALIDATION********')\n",
    "\n",
    "            for batch in tqdm(tokenize_batch(test_df), total=int(len(test_df)/batchsize)):\n",
    "\n",
    "                input_ids, attention_mask, labels = batch\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(input_ids, attention_mask)\n",
    "                    logits = outputs\n",
    "\n",
    "                    # Calculate predictions\n",
    "                    predictions = torch.argmax(logits, dim=-1)\n",
    "                    if epochs == epoch + 1:\n",
    "                        pred_list.extend(np.array(predictions))\n",
    "                        label_list.extend(np.array(labels))\n",
    "                    \n",
    "\n",
    "                    # Calculate accuracy\n",
    "                    total_correct += (predictions == labels).sum().item()\n",
    "\n",
    "                loss = criterion(logits, labels)\n",
    "                total_eval_loss += loss.item()\n",
    "\n",
    "            # Print evaluation metrics\n",
    "            eval_loss = total_eval_loss / len(test_df)\n",
    "            accuracy = total_correct / len(test_df) * 100\n",
    "            print(f\"Epoch {epoch+1}/{epochs} | Eval Loss: {eval_loss:.4f} | Accuracy: {accuracy:.2f}%\")\n",
    "            \n",
    "        return pred_list, label_list\n",
    "            \n",
    "    pred_list, label_list = train_validate(model, optimizer, criterion ,epochs, device)\n",
    "    \n",
    "    return model, pred_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfbaaf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********EPOCH 1 TRAINING********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "213it [04:57,  1.40s/it]                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | Average Loss: 0.0577\n",
      "********EPOCH 1 VALIDATION********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [00:12,  2.96it/s]                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | Eval Loss: 0.0349 | Accuracy: 67.50%\n",
      "********EPOCH 2 TRAINING********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "213it [05:04,  1.43s/it]                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 | Average Loss: 0.0276\n",
      "********EPOCH 2 VALIDATION********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [00:12,  3.06it/s]                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 | Eval Loss: 0.0272 | Accuracy: 72.33%\n",
      "********EPOCH 3 TRAINING********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "213it [05:01,  1.42s/it]                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 | Average Loss: 0.0179\n",
      "********EPOCH 3 VALIDATION********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [00:13,  2.89it/s]                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 | Eval Loss: 0.0254 | Accuracy: 75.58%\n",
      "********EPOCH 4 TRAINING********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "213it [05:07,  1.45s/it]                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 | Average Loss: 0.0116\n",
      "********EPOCH 4 VALIDATION********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [00:12,  3.00it/s]                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 | Eval Loss: 0.0257 | Accuracy: 76.50%\n",
      "********EPOCH 5 TRAINING********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "213it [04:57,  1.40s/it]                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 | Average Loss: 0.0071\n",
      "********EPOCH 5 VALIDATION********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [00:12,  2.96it/s]                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 | Eval Loss: 0.0274 | Accuracy: 78.08%\n"
     ]
    }
   ],
   "source": [
    "model, y_pred, y = bert_model(X_train, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "735242f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83        49\n",
      "           1       0.93      0.83      0.88       107\n",
      "           2       0.79      0.86      0.82        73\n",
      "           3       0.76      0.73      0.74        70\n",
      "           4       0.79      0.84      0.81        62\n",
      "           5       0.90      0.87      0.88        30\n",
      "           6       0.82      0.82      0.82       119\n",
      "           8       0.73      0.72      0.73        86\n",
      "           9       0.82      0.64      0.72        22\n",
      "          10       0.78      0.64      0.70        11\n",
      "          11       0.87      0.86      0.86        63\n",
      "          12       1.00      0.64      0.78        14\n",
      "          13       0.86      0.85      0.86        95\n",
      "          14       0.86      0.83      0.84        78\n",
      "          15       0.81      0.81      0.81        21\n",
      "          16       0.73      0.80      0.77        45\n",
      "          17       0.88      0.78      0.82        63\n",
      "          18       0.58      0.63      0.60       192\n",
      "\n",
      "    accuracy                           0.78      1200\n",
      "   macro avg       0.82      0.78      0.79      1200\n",
      "weighted avg       0.79      0.78      0.78      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03fa71ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print (len(train_df[train_df['relation']==7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d3a92b",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fbe8ce87",
   "metadata": {},
   "source": [
    "1. Relation type 'Other' i.e. 18 has no specific pattern, and is hence the most difficult to predict. But bert understands the other category better than svm.\n",
    "2. Only 1 training data is available for relation type 7. Hence, it has a very poor prediction.\n",
    "3. Overall, both svm and bert did perform similar with bert slightly better, while in few categories svm outperformed bert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52c698b",
   "metadata": {},
   "source": [
    "### Test Case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6eff4ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_df, model):\n",
    "    \n",
    "    def tokenize_batch(df, batchsize=32):\n",
    "        tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "        tokenized_inputs = tokenizer(df['trimmed_sentence_wdef'].tolist(),\n",
    "                                     df['corrected_e1'].tolist(),\n",
    "                                     df['corrected_e2'].tolist(),\n",
    "                                     df['e1_dep_token'].tolist(),\n",
    "                                     df['e2_dep_token'].tolist(),\n",
    "                                     padding=True, \n",
    "                                     truncation=True,\n",
    "                                     return_tensors='pt')\n",
    "        labels =  torch.tensor(df['relation'].tolist())\n",
    "\n",
    "        \n",
    "        dataset = TensorDataset(tokenized_inputs['input_ids'], tokenized_inputs['attention_mask'], labels)\n",
    "        loader = DataLoader(dataset, batch_size=batchsize)\n",
    "        \n",
    "        return loader\n",
    "    \n",
    "    pred_list = []\n",
    "    label_list = []\n",
    "    batchsize = 32        \n",
    "    for batch in tqdm(tokenize_batch(test_df), total=int(len(test_df)/batchsize)):\n",
    "\n",
    "        input_ids, attention_mask, labels = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "\n",
    "            predictions = torch.argmax(outputs, dim=-1)\n",
    "\n",
    "            pred_list.extend(np.array(predictions))\n",
    "            label_list.extend(np.array(labels))\n",
    "    \n",
    "    return pred_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c45d37e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "85it [00:37,  2.25it/s]                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87       134\n",
      "           1       0.88      0.86      0.87       194\n",
      "           2       0.83      0.82      0.83       162\n",
      "           3       0.76      0.70      0.73       150\n",
      "           4       0.83      0.88      0.86       153\n",
      "           5       0.71      0.77      0.74        39\n",
      "           6       0.79      0.87      0.83       291\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.84      0.73      0.78       211\n",
      "           9       0.88      0.79      0.83        47\n",
      "          10       0.88      0.64      0.74        22\n",
      "          11       0.75      0.63      0.69       134\n",
      "          12       0.73      0.59      0.66        32\n",
      "          13       0.89      0.82      0.85       201\n",
      "          14       0.83      0.84      0.83       210\n",
      "          15       0.81      0.75      0.78        51\n",
      "          16       0.82      0.85      0.84       108\n",
      "          17       0.76      0.84      0.80       123\n",
      "          18       0.55      0.60      0.58       454\n",
      "\n",
      "    accuracy                           0.77      2717\n",
      "   macro avg       0.76      0.73      0.74      2717\n",
      "weighted avg       0.78      0.77      0.77      2717\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred, y = test_model(test_df, model)\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e9bf44",
   "metadata": {},
   "source": [
    "# Inference Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bf6b221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relation</th>\n",
       "      <th>relation type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Cause-Effect(e1,e2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cause-Effect(e2,e1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Component-Whole(e1,e2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Component-Whole(e2,e1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Content-Container(e1,e2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Content-Container(e2,e1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Entity-Destination(e1,e2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Entity-Destination(e2,e1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Entity-Origin(e1,e2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Entity-Origin(e2,e1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Instrument-Agency(e1,e2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Instrument-Agency(e2,e1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Member-Collection(e1,e2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Member-Collection(e2,e1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Message-Topic(e1,e2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Message-Topic(e2,e1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Product-Producer(e1,e2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Product-Producer(e2,e1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    relation              relation type\n",
       "0          0        Cause-Effect(e1,e2)\n",
       "1          1        Cause-Effect(e2,e1)\n",
       "2          2     Component-Whole(e1,e2)\n",
       "3          3     Component-Whole(e2,e1)\n",
       "4          4   Content-Container(e1,e2)\n",
       "5          5   Content-Container(e2,e1)\n",
       "6          6  Entity-Destination(e1,e2)\n",
       "7          7  Entity-Destination(e2,e1)\n",
       "8          8       Entity-Origin(e1,e2)\n",
       "9          9       Entity-Origin(e2,e1)\n",
       "10        10   Instrument-Agency(e1,e2)\n",
       "11        11   Instrument-Agency(e2,e1)\n",
       "12        12   Member-Collection(e1,e2)\n",
       "13        13   Member-Collection(e2,e1)\n",
       "14        14       Message-Topic(e1,e2)\n",
       "15        15       Message-Topic(e2,e1)\n",
       "16        16    Product-Producer(e1,e2)\n",
       "17        17    Product-Producer(e2,e1)\n",
       "18        18                      Other"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "relation_name = {\n",
    "0: 'Cause-Effect(e1,e2)',\n",
    "1: 'Cause-Effect(e2,e1)',\n",
    "2: 'Component-Whole(e1,e2)',\n",
    "3: 'Component-Whole(e2,e1)',\n",
    "4: 'Content-Container(e1,e2)',\n",
    "5: 'Content-Container(e2,e1)',\n",
    "6: 'Entity-Destination(e1,e2)',\n",
    "7: 'Entity-Destination(e2,e1)',\n",
    "8: 'Entity-Origin(e1,e2)',\n",
    "9: 'Entity-Origin(e2,e1)',\n",
    "10: 'Instrument-Agency(e1,e2)', \n",
    "11: 'Instrument-Agency(e2,e1)',\n",
    "12: 'Member-Collection(e1,e2)',\n",
    "13: 'Member-Collection(e2,e1)',\n",
    "14: 'Message-Topic(e1,e2)',\n",
    "15: 'Message-Topic(e2,e1)',\n",
    "16: 'Product-Producer(e1,e2)',\n",
    "17: 'Product-Producer(e2,e1)',\n",
    "18: 'Other'\n",
    "}\n",
    "\n",
    "display(pd.DataFrame([(key, value) for key, value in relation_name.items()], columns=[\"relation\", \"relation type\"]))\n",
    "\n",
    "def inference_mode(sentence):\n",
    "    if type(sentence)==str:\n",
    "        sentence = [sentence]\n",
    "    df = pd.DataFrame(sentence, columns = ['sentence'])\n",
    "    df = preprocess_data(df)\n",
    "    \n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "    tokenized_inputs = tokenizer(df['corrected_sentence'].tolist(),\n",
    "                                     df['corrected_e1'].tolist(),\n",
    "                                     df['corrected_e2'].tolist(),\n",
    "                                     df['e1_dep_token'].tolist(),\n",
    "                                     df['e2_dep_token'].tolist(),\n",
    "                                     padding=True, \n",
    "                                     truncation=True,\n",
    "                                     return_tensors='pt')\n",
    "    \n",
    "    output = model(tokenized_inputs['input_ids'], tokenized_inputs['attention_mask'])\n",
    "\n",
    "    predicted_label = torch.argmax(output, dim=-1)\n",
    "    df['predicted_relation'] = predicted_label\n",
    "    df['predicted_relation_type'] = df['predicted_relation'].map(relation_name)\n",
    "    return df[['sentence','predicted_relation_type']]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75404b9",
   "metadata": {},
   "source": [
    "### Try Your Sentence"
   ]
  },
  {
   "cell_type": "raw",
   "id": "95e4584c",
   "metadata": {},
   "source": [
    "NOTE:\n",
    "1. Input can be passed either as string or list of strings\n",
    "2. entites should be enclosed in the format shown: '<e1>Global warming</e1> is a result of <e2>deforestation</e2>.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1f3752f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f531bf76a02472f9f4691f4ffbdcc7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e11c7d80884370abf08b19dad69f78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9afeaaa853ca4184b9cf27b38c45cd5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4917c481e72642cea5a77e0b62b655a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2078c2b9edd74fdf8e5586175df58117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50f576cafd94b4aa25ac7aeeb81b0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e39f027fde4aa8a2b15209a801fbf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>predicted_relation_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;e1&gt;Apple&lt;/e1&gt; produces &lt;e2&gt;Iphone&lt;/e2&gt;.</td>\n",
       "      <td>Product-Producer(e2,e1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   sentence  predicted_relation_type\n",
       "0  <e1>Apple</e1> produces <e2>Iphone</e2>.  Product-Producer(e2,e1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display (inference_mode('<e1>Apple</e1> produces <e2>Iphone</e2>.'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
